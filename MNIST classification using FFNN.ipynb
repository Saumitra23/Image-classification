{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to convert the labels into categorical data for processing\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28) (60000,)\n",
      "Test data shape: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape:',train_images.shape, train_labels.shape)\n",
    "print('Test data shape:',test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique labels in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no of outputs: 10\n",
      "output classes: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ground Truth : 7')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "classes = np.unique(train_labels)\n",
    "classes_num = len(classes)\n",
    "print('total no of outputs:',classes_num)\n",
    "print('output classes:',classes)\n",
    "\n",
    "plt.figure(figsize=[10,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(train_images[0,:,:],cmap='gray')\n",
    "plt.title('Ground truth : {}'.format(train_labels[0]))\n",
    "\n",
    "# Display the first image in test data\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(test_images[0,:,:],cmap='gray')\n",
    "plt.title('Ground Truth : {}'.format(test_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Process the data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change from matrix to array of dimension 28x28 to array of dimension 784\n",
    "# it will be fed to the network as a single feature\n",
    "dim_data = np.prod(train_images.shape[1:])\n",
    "train_data = train_images.reshape(train_images.shape[0], dim_data)\n",
    "test_data = test_images.reshape(test_images.shape[0], dim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to float datatype and scale values b/w 0 to 1\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert the labels from integer to categorical ( one-hot ) encoding\n",
    "since that is the format required by Keras to perform multiclass\n",
    "classification. One-hot encoding is a type of boolean representation of \n",
    "integer data. It converts the integer to an array of all zeros except a \n",
    "1 at the index of the integer.\n",
    "For example, using a one-hot encoding for 10 classes, \n",
    "the integer 5 will be encoded as 0000010000.\n",
    "\"\"\"\n",
    "# Change the labels from integer to categorical data\n",
    "train_labels_one_hot = to_categorical(train_labels)\n",
    "test_labels_one_hot = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Creating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "we will be using a network with 2 hidden layers and an output layer\n",
    "with 10 units. The number of units in the hidden layers is \n",
    "kept to be 512. The input to the network is the 784-dimensional array \n",
    "converted from the 28×28 image.\n",
    "\n",
    "We will use the Sequential model for building the network.\n",
    "In the Sequential model, we can just stack up layers by adding the desired \n",
    "layer one by one. We use the Dense layer, also called fully connected layer\n",
    "since we are building a feedforward network in which all the neurons from one layer\n",
    "are connected to the neurons in the previous layer. Apart from the Dense layer,\n",
    "we add the ReLU activation function which is required to introduce \n",
    "non-linearity to the model. This will help the network learn non-linear\n",
    "decision boundaries. The last layer is a softmax layer as it is a multiclass\n",
    "classification problem. For binary classification, we can use sigmoid\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu',input_shape = (dim_data,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(classes_num, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Configure the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "configure the optimizer to be rmsprop. We also specify \n",
    "the loss type which is categorical cross entropy which is used \n",
    "for multiclass classification. We also specify the metrics \n",
    "( accuracy in this case ) which we want to track during the \n",
    "training process. You can also try using any other optimizer\n",
    "such as adam or SGD.\n",
    "\"\"\"\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 6.2810 - accuracy: 0.8719 - val_loss: 0.7036 - val_accuracy: 0.9243\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.4270 - accuracy: 0.9455 - val_loss: 0.4488 - val_accuracy: 0.9373\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.2461 - accuracy: 0.9587 - val_loss: 0.5398 - val_accuracy: 0.9189\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.1983 - accuracy: 0.9659 - val_loss: 0.3368 - val_accuracy: 0.9518\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.1685 - accuracy: 0.9703 - val_loss: 0.2849 - val_accuracy: 0.9624\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.1469 - accuracy: 0.9755 - val_loss: 0.3262 - val_accuracy: 0.9628\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.1417 - accuracy: 0.9771 - val_loss: 0.2726 - val_accuracy: 0.9653\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.1299 - accuracy: 0.9808 - val_loss: 0.4526 - val_accuracy: 0.9537\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.1145 - accuracy: 0.9821 - val_loss: 0.2943 - val_accuracy: 0.9698\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.1106 - accuracy: 0.9844 - val_loss: 0.3843 - val_accuracy: 0.9727\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.1250 - accuracy: 0.9852 - val_loss: 0.4193 - val_accuracy: 0.9642\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.1131 - accuracy: 0.9864 - val_loss: 0.4112 - val_accuracy: 0.9662\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.1166 - accuracy: 0.9869 - val_loss: 0.4439 - val_accuracy: 0.9727\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.1053 - accuracy: 0.9888 - val_loss: 0.4997 - val_accuracy: 0.9693\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.1121 - accuracy: 0.9888 - val_loss: 0.4913 - val_accuracy: 0.9730\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0980 - accuracy: 0.9899 - val_loss: 0.4562 - val_accuracy: 0.9769\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.1186 - accuracy: 0.9902 - val_loss: 0.6405 - val_accuracy: 0.9732\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.0985 - accuracy: 0.9915 - val_loss: 0.6298 - val_accuracy: 0.9749\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0978 - accuracy: 0.9919 - val_loss: 0.5442 - val_accuracy: 0.9788\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0914 - accuracy: 0.9921 - val_loss: 0.6483 - val_accuracy: 0.9760\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The network is ready to get trained. This is done using the fit()\n",
    "function in Keras. We specify the number of epochs as 20.\n",
    "This means that the whole dataset will be fed to the network 20 times.\n",
    "We will be using the test data for validation.\n",
    "\"\"\"\n",
    "\n",
    "history = model.fit(train_data, train_labels_one_hot, batch_size=256,\n",
    "                    epochs=20,verbose=1,\n",
    "                    validation_data=(test_data,test_labels_one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6483 - accuracy: 0.9760\n",
      "Evaluation result on test data : Loss = 0.6483175158500671, accuracy = 0.9760000109672546\n"
     ]
    }
   ],
   "source": [
    "# we check the performance on the whole test data\n",
    "# using the evaluate() method\n",
    "\n",
    "[test_loss, test_acc] = model.evaluate(test_data,test_labels_one_hot)\n",
    "print(\"Evaluation result on test data : Loss = {}, accuracy = {}\"\n",
    "      .format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> check for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy curves')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The fit() function returns a history object which has a\n",
    "dictionary of all the metrics which were required to be tracked\n",
    "during training. We can use the data in the history object to\n",
    "plot the loss and accuracy curves to check how the training process went.\n",
    "You can use the history.history.keys() function to check what\n",
    "metrics are present in the history. It should look like the following:\n",
    "\n",
    "['accuracy', 'loss', 'val_accuracy', 'val_loss']\n",
    "\"\"\"\n",
    "\n",
    "# plot the loss curves\n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss','Validation loss'],fontsize=18)\n",
    "plt.xlabel('Epochs',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss curves',fontsize=16)\n",
    "\n",
    "#plot th accuracy curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['accuracy'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_accuracy'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy','Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfitting\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Although the accuracy obtained above is very good,\n",
    "if you see the loss and accuracy curves in the above figures,\n",
    "you’ll notice that the validation loss initially decrease,\n",
    "but then it starts increasing gradually.\n",
    "Also, there is a substantial difference between the training\n",
    "and test accuracy. This is a clear sign of Overfitting\n",
    "which means that the network has memorized the training \n",
    "data very well, but is not guaranteed to work on unseen data.\n",
    "Thus, the difference in the training and test accuracy.\n",
    "\"\"\"\n",
    "print('Overfitting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding regularization to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Overfitting occurs mainly because the network parameters are getting too biased towards the training data. We can add a dropout layer to overcome this problem to a certain extent. In case of dropout, a fraction of neurons is randomly turned off during the training process, reducing the dependency on the training set by some amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model_reg = Sequential()\n",
    "model_reg.add(Dense(512, activation='relu', input_shape=(dim_data,)))\n",
    "model_reg.add(Dropout(0.4))\n",
    "model_reg.add(Dense(512, activation='relu'))\n",
    "model_reg.add(Dropout(0.4))\n",
    "model_reg.add(Dense(classes_num, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check performance after regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg.compile(optimizer='rmsprop',loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 7s 28ms/step - loss: 6.4118 - accuracy: 0.8041 - val_loss: 0.6085 - val_accuracy: 0.9345\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 1.0034 - accuracy: 0.8885 - val_loss: 0.2713 - val_accuracy: 0.9437\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 7s 28ms/step - loss: 0.5317 - accuracy: 0.9047 - val_loss: 0.2130 - val_accuracy: 0.9436\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 7s 28ms/step - loss: 0.4227 - accuracy: 0.9149 - val_loss: 0.1832 - val_accuracy: 0.9546\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 6s 27ms/step - loss: 0.3662 - accuracy: 0.9243 - val_loss: 0.1535 - val_accuracy: 0.9582\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.3257 - accuracy: 0.9307 - val_loss: 0.1478 - val_accuracy: 0.9622\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.3144 - accuracy: 0.9370 - val_loss: 0.1634 - val_accuracy: 0.9621\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.2937 - accuracy: 0.9398 - val_loss: 0.1523 - val_accuracy: 0.9643\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 6s 28ms/step - loss: 0.2765 - accuracy: 0.9424 - val_loss: 0.1523 - val_accuracy: 0.9689\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.2741 - accuracy: 0.9451 - val_loss: 0.1743 - val_accuracy: 0.9688\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.2702 - accuracy: 0.9458 - val_loss: 0.1484 - val_accuracy: 0.9699\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.2623 - accuracy: 0.9484 - val_loss: 0.1644 - val_accuracy: 0.9725\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.2540 - accuracy: 0.9509 - val_loss: 0.1661 - val_accuracy: 0.9686\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.2434 - accuracy: 0.9521 - val_loss: 0.1851 - val_accuracy: 0.9665\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.2503 - accuracy: 0.9519 - val_loss: 0.1668 - val_accuracy: 0.9731\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.2501 - accuracy: 0.9534 - val_loss: 0.1700 - val_accuracy: 0.9724\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.2407 - accuracy: 0.9543 - val_loss: 0.1921 - val_accuracy: 0.9720\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.2450 - accuracy: 0.9548 - val_loss: 0.2005 - val_accuracy: 0.9732\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.2453 - accuracy: 0.9547 - val_loss: 0.1981 - val_accuracy: 0.9707\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.2366 - accuracy: 0.9540 - val_loss: 0.2003 - val_accuracy: 0.9705\n"
     ]
    }
   ],
   "source": [
    "history_reg = model_reg.fit(train_data, train_labels_one_hot, batch_size=256,\n",
    "                    epochs=20,verbose=1,\n",
    "                    validation_data=(test_data,test_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy Curves')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot the Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history_reg.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history_reg.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=16)\n",
    "\n",
    "#Plot the Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history_reg.history['accuracy'],'r',linewidth=3.0)\n",
    "plt.plot(history_reg.history['val_accuracy'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our first image in the test set is number 7\n",
    "# let's see what our model predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-f51f081327fb>:3: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Model prediction:4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, 'Ground truth: 4')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the image\n",
    "print('Model prediction:{}'.format(model_reg.predict_classes\n",
    "                                  (test_data[[4],:])[0]))\n",
    "\n",
    "# display the predicted image\n",
    "plt.imshow(test_images[4],cmap='gray')\n",
    "plt.title('Ground truth: {}'.format(test_labels[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2336685e-24, 2.6785913e-14, 4.8821407e-13, 3.7296501e-23,\n",
       "        1.0000000e+00, 2.4403984e-17, 1.1423391e-18, 1.1998451e-10,\n",
       "        4.2371769e-15, 5.1824118e-09]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction score\n",
    "model_reg.predict(test_data[[4],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above we can see that the 5th index predicts a \n",
    "# score of 1 which means the confidence of being \n",
    "# digit 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I tried this model using relu, sigmoid and tanh in which relu gave best accuracy on training data but also resulted into overfitting.\n",
    "# After regularization it showed the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
